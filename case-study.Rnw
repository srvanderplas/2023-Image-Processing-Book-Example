\documentclass{article}
\usepackage{cleveref}
\usepackage{graphicx}
\begin{document}


\section{Shoe Print Processing}

This case study will focus on the challenges of analyzing image data that has repetitive patterns. 
The images in question are from a study designed to examine how athletic shoes wear over time, with the goal of creating an open data set that could be used to test the accuracy of forensic matching algorithms. 
Here, we have three prints from a single right Nike Winflow shoe (size Men's 10.5) created using paper and fingerprint powder, taken in January, February, and April of 2018. 

One important goal of this study was to facilitate analysis of the development and wear of Randomly Acquired Characteristics (RACs) - small cuts and other damage to shoe soles which accumulate (and wear away) as a shoe is worn. These characteristics are typically tiny - millimeters in size, which is why fingerprint powder is used to record these prints: it is capable of providing such details. 

This case study will use R for image processing; code is available at ...
<<setup, include = F>>=
knitr::opts_chunk$set(echo = F, message = F, warning = F, dpi = 300)
@

<<initial>>=
#| fig.width = 7,
#| fig.height = 4,
#| fig.cap = "Three high-resolution scans of paper-and-powder shoe prints taken of the same shoe over a 4-month period as the shoe was worn."
library(tidyverse)
library(imager)

im <- load.dir("orig-images/", "2018.*6_1_1.*")
names(im) <- str_replace(names(im), "\\d{6}R_(\\d{8})_.*", "\\1")
im <- map_il(im, grayscale)
plot(im, "row")
@

Several visual artifacts can be noticed from a cursory inspection of these images:

\begin{itemize}
\item There is a label present in the corner of each image with the shoe's ID code and other metadata.
\item The paper is not always squared up against the scanner
\item There are fingerprint smudges on the edges of the paper where the paper was held down while the print was taken.
\item There are blobs of fingerprint powder which were dislodged from the shoe during the print process which are not part of the shoe tread pattern (e.g. around the heel in the middle figure).
\item The images have already been normalized (presumably by the scanner) - the labels are actually the same color across images, but they do not appear to be the same color due to scanner post-processing.
\end{itemize}

An interesting facet of these images is that because they are scans of impressions recorded with fingerprint powder, at an extreme zoom level, there is relatively little cohesiveness in the dark areas of each print, as shown in \Cref{fig:shoe-zoom}.

<<zoom-in>>=
#| fig.cap = "A 200 x 200 pixel subset of the shoe on the left, showing that the shapes are not typically solid in these high-resolution prints.\\label{fig:shoe-zoom}"
# plot(as.cimg(im[[1]][850:1050,2100:2300]))
plot(as.cimg(im[[1]][380:580,2100:2300]))
@

In order to clean up these images, we must at minimum perform the following steps:

\begin{enumerate}
\item Remove the label
\item Remove the scanner bed edges
\item Remove the background (without preserving any of the background pattern, if possible)
\item Remove smudges, fingerprints, and if possible, "blobs" of fingerprint powder that are not part of a shoeprint, without compromising the small details such as those shown in \Cref{fig:shoe-zoom}. 
\end{enumerate}

Before we start in on the identified processing pipeline, we can speed up the processing of the image by reducing the number of colors. 
As these images are already greyscale, we can further reduce the image size by clustering the colors present in the image and reducing the image to the most common $k=8$ clusters of intensity identified using k-means. The result is shown in \Cref{fig:shoe-quantize}.

<<quantize>>=
#| fig.width = 7,
#| fig.height = 4,
#| fig.cap = "Shoe prints after image quantization using k-means with $k=8$. \\label{fig:shoe-quantize}"
#| 
#' Limit the number of colors in the image
#' 
#' @param shoe cimage
#' @param n number of colors in returned image
#' @param return cimg
#' @import imager
#' @import dplyr
#' @importFrom tidyr gather
#' @export
quantize_colors <- function(shoe, n = 16) {
  if (max(shoe) > 255) {
    shoe <- renorm(shoe)
  }
  # https://lumiamitie.github.io/r/imager-color-quantization/
  
  shoe_df <- shoe %>%
    as.data.frame(wide = 'c') %>%
    tbl_df()
  
  shoe_cluster <- suppressMessages(
    shoe_df %>% select(-x, -y) %>% kmeans(centers = n)
  )
  
  shoe_df %>%
    mutate(label = as.character(shoe_cluster$cluster)) %>%
    select(x, y, label) %>%
    left_join(
      shoe_cluster$centers %>% 
        tbl_df %>% 
        mutate(label = as.character(row_number())), 
      by = "label") %>%
    select(-label) %>%
    tidyr::gather(key = 'cc', value = 'value', starts_with('c.')) %>%
    mutate(cc = as.integer(gsub('c\\.', '', cc))) %>%
    as.cimg(dim = dim(shoe))
}

shoe <- map_il(im, quantize_colors, 8)
plot(shoe, "row")
@

To identify the label, we use the following steps:
\begin{itemize}
\item Threshold the image using 10\% of the maximum value (white is high)
\item Clean up this threshold by growing the area by 100 pixels and shrinking by 150 pixels (this removes most shoe-related blobs)
\item Label continuous areas and select the second-largest labeled area (the largest is the background)
\item Check that the selected region has a reasonable area relative to the total image
\item Remove the selected region by replacing it with the maximum pixel value in the image
\end{itemize}

\Cref{fig:shoe-nolabel} shows the images with the data labels removed.

<<>>=
#| fig.width = 7,
#| fig.height = 4,
#| fig.cap = "Shoe prints after label removal. \\label{fig:shoe-nolabel}"

#' Removes a label from the shoeprint scan
#' 
#' This algorithm assumes the label will be larger than 50 px and will be dark
#' 
#' @param shoe cimg image type
#' @param ... arguments to pass to imager::threshold
#' @return cimg with any label which may be present removed
#' @import imager
#' @export
remove_print_label <- function(shoe, ...) {
  
  if (max(shoe) > 255) {
    shoe <- renorm(shoe)
  }
  
  if (!exists("thr")) {
    thr <- "10%"
  }
  replace_color <- max(shoe) 
  
  # This identifies the label if it is bigger than 50 px and dark
  z <- threshold(shoe, thr = thr) %>%
    grow(100) %>%
    shrink(150)
  
  zlab <- label(z) # Label continuous areas
  chunks <- table(zlab) %>% sort() %>% rev() # Get frequencies/areas in correct order
  chunks <- chunks[-1] # Remove largest chunk - background
  
  largest_region <- zlab == as.numeric(names(chunks)[1])
  
  # Only remove label if it has a reasonable area
  islabeled <- mean(!largest_region) < .98
  
  if (islabeled) {
    shoe[largest_region] <- replace_color
  }
  
  return(shoe)
}

shoe_nolab <- map_il(shoe, remove_print_label)
plot(shoe_nolab, "row")
@

Then, we can attempt to remove background information such as the scanner bed. As some of the prints in this study go right up to the edge of the paper (e.g. the bottom of the leftmost image), simply trimming the image may result in removing portions of the shoe print.

Removing local background information is performed using the following steps:
\begin{itemize}
\item Divide the shoe up into a series of $n\times n$ sub-images ($n = 20$ by default)
\item Take the median value of the sub-image
\item Replace any pixels lighter than the median value with white
\item Reassemble the image
\end{itemize}

This method of background removal handles ripples and other nonlinear issues in the background variation; the results are shown in \Cref{fig:shoe-lbg}.
Determining a good procedure for background removal is a trial-and-error process; finding a method that works across many different images automatically can be extremely difficult. 
However, as with many image processing methods, complex techniques are often simply a combination of simple operations and feature engineering. 

<<>>=
#| fig.width = 7,
#| fig.height = 4,
#| fig.cap = "Shoe prints after local background removal. \\label{fig:shoe-lbg}"

#' Remove local background 
#' 
#' @param shoe cimage
#' @param n number of sub-images to use. shoe is divided into an n x n grid for local background computation
#' @param threshold if a pixel is within threshold of the median pixel value, it should be set to white as well
#' @return a cimg
#' @export
#' @import imager
#' @importFrom purrr map_df
#' @importFrom dplyr data_frame
#' @importFrom purrr map
remove_local_background <- function(shoe, n = 10, threshold = 10, borderarea = 100, borderonly = F) {
  grid_shoe <- tibble(
    x = 1:n,
    xstr = imsplit(renorm(shoe), axis = "x", nb = n)
  ) %>%
    mutate(
      ydat = purrr::map(xstr, ~tibble(y = 1:n, xystr = as.list(imsplit(., "y", nb = n))))
    ) %>%
    unnest("ydat") %>%
    mutate(
      medvalue = map_dbl(xystr, median),
      normshoe = map2(xystr, medvalue, function(tmp, med) {
        tmp2 <- tmp
        tmp2[tmp >= med] <- 255
        as.cimg(tmp2)
      })
    )
    #     split(.$x) %>%
    # map_df(.x = ., .f = function(zz) {
    #   tmp <- imsplit(zz$xstr[[1]], axis = "y", nb = n)
    #   data_frame(
    #     x = zz$x,
    #     y = 1:n,
    #     xyshoe = tmp,
    #     # Get local background values
    #     medvalue = sapply(tmp, median),
    #     # Replace local background with white
    #     normshoe = lapply(tmp, function(x) {y <- x; y[(x >= median(x))] <- 255; y[abs(y - median(x)) < threshold] <- 255; y})
    #   )
    # })
  
  center_shoe <- !px.borders(shoe, n = borderarea)
  
  shoe_reassemble <- select(grid_shoe, x, y, normshoe) %>%
    split(.$x) %>%
    map(~imappend(imlist = .$normshoe, axis = "y")) %>%
    imappend(imlist = ., axis = "x") %>%
    renorm()
  
  if (borderonly) {
    shoe_fixpieces <- renorm(shoe)
    shoe_fixpieces[!center_shoe] <- shoe_reassemble[!center_shoe]
  } else {
    shoe_fixpieces <- shoe_reassemble
  }

  shoe_fixpieces %>% renorm()
}

shoe_lbg <- map_il(shoe_nolab, remove_local_background, n=20)
plot(shoe_lbg, "row")
@

The next step in our cleaning process is to remove the border regions. 
It would be reasonable to consider cropping the image by a certain number of pixels on all sides, but this may potentially remove portions of the shoe sole. 

Instead, let's consider a special type of adaptive cropping operation: one which splits the image into halves and identifies a region towards the extreme of the half which has mean (row or column-wise) pixel value within a certain tolerance of the maximum value. 

If we applied this cropping operation in X and Y separately, we could then get the "important" part of the image without the edge regions. 

<<>>=
#| fig.width = 7,
#| fig.height = 4,
#| fig.cap = "Shoe prints after the custom cropping function has been applied. \\label{fig:shoe-cropping}"

#' Crop shoe border
#' 
#' Remove most of the white space around the shoe. This function splits the image
#' into two pieces at the middle, then uses the mean intensity (0-255) in the chosen dimension
#' to determine where the image should be cropped. The region to crop is the value closest to the 
#' center of the image which is within tol of the maximum mean intensity found in the
#' image. 
#' @param shoe cimg
#' @param axis either "x", "y", or "xy"
#' @param sigma radius to use for blurring the image
#' @param tol change the tolerance of the cropping function
#' @export
#' @import imager
crop_border <- function(shoe, axis = "xy", sigma = 5, tol = 0.04) {
  stopifnot(axis %in% c("x", "y", "xy"))
  
  if (axis == "xy") {
    axis = c("x", "y")
  }
  
  modimg <- shoe
  
  # Deal with x first
  if ("x" %in% axis) {
    tshoe_x <- imsplit(modimg, "x", 2)
    tshoe_x[[2]] <- mirror(tshoe_x[[2]], "x")
    
    tshoe_xfix <- lapply(tshoe_x, function(xx) {
      xxmod <- isoblur(xx, sigma)
      yy <- apply(xxmod, 1, mean) 
      zz <- which(abs(yy - max(yy)) < tol) %>% max()
      
      # Don't crop if removing more than 25% of the image
      if (zz > .5*length(yy)) {
        zz <-  -1
      }
      imsub(xx, x > (zz + 1)) 
    }) 
    
    tshoe_xfix[[2]] <- mirror(tshoe_xfix[[2]], "x")
    modimg <- imappend(tshoe_xfix, axis = "x")
    rm(tshoe_x, tshoe_xfix)
  }
  
  if ("y" %in% axis) {
    tshoe_y <- imsplit(modimg, "y", 2)
    tshoe_y[[2]] <- mirror(tshoe_y[[2]], "y")
    
    tshoe_yfix <- lapply(tshoe_y, function(xx) {
      xxmod <- isoblur(xx, sigma)
      yy <- apply(xxmod, 2, mean) 
      zz <- which(abs(yy - max(yy)) < tol) %>% max()   
      
      # Don't crop if removing more than 25% of the image
      if (zz > .5*length(yy)) {
        zz <-  -1
      }
      imsub(xx, y > (zz + 1)) 
    }) 
    
    tshoe_yfix[[2]] <- mirror(tshoe_yfix[[2]], "y")
    modimg <- imappend(tshoe_yfix, axis = "y")
    rm(tshoe_y, tshoe_yfix)
  }
  
  return(modimg)
}

shoe_crop <- map_il(shoe_lbg, crop_border)
plot(shoe_crop, "row")
@


This operation is certainly not perfect (it cannot handle the smudges along the right side of the first image), but it is at least useful for removing the edges of the scan without compromising the shoeprint.

Now, at this point, you may be wondering why someone would go to all the trouble of writing functions to perform this complex series of operations, when it would be fairly straightforward to manually clean these pictures in an image editing program such as Photoshop.
The answer is found in the scale of the data: the study these example images are taken from involved 160 pairs of shoes, with 2 replicates of each shoe in the pair, taken at least 4 and sometimes 5 times. 
In total, that is at least 2560 images. 
Manually editing those images would not only take an extreme amount of time, but would also not be reproducible. 
In some circumstances, it is far faster to write code to clean repetitive images than it is to manually edit said images.
\end{document}
